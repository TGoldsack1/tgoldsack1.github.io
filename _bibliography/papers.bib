---
---



@inproceedings{emnlp2023a,
    abbr="EMNLP2023",
    selected=True,
    title = "Enhancing Biomedical Lay Summarisation with External Knowledge Graphs",
    author = "Goldsack, Tomas  and
      Zhang, Zhihao  and
      Tang, Chen  and
      Scarton, Carolina and
      Lin, Chenghua",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing.",
    month = December,
    year = "2023",
    publisher = "Association for Computational Linguistics",
    abstract = "Previous approaches for automatic lay summarisation are exclusively reliant on the source article that, given it is written for a technical audience (e.g., researchers), is unlikely to explicitly define all technical concepts or state all of the background information that is relevant for a lay audience. We address this issue by augmenting eLife, an existing biomedical lay summarisation dataset, with article-specific knowledge graphs, each containing detailed information on relevant biomedical concepts. Using both automatic and human evaluations, we systematically investigate the effectiveness of three different approaches for incorporating knowledge graphs within lay summarisation models, with each method targeting a distinct area of the encoder-decoder model architecture. Our results confirm that integrating graph-based domain knowledge can significantly benefit lay summarisation by substantially increasing the readability of generated text and improving the explanation of technical concepts.",
}

@inproceedings{emnlp2023b,
    abbr="EMNLP2023",
    selected=True,
    title = "Improving Biomedical Abstractive Summarisation with Knowledge Aggregation from Citation Papers",
    author = "Tang, Chen  and
      Wang, Shun  and
      Goldsack, Tomas and
      Lin, Chenghua",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing.",
    month = December,
    year = "2023",
    publisher = "Association for Computational Linguistics",
    abstract = "Abstracts derived from biomedical literature possess distinct domain-specific characteristics, including specialized writing styles and biomedical terminologies, which necessitate a deep understanding of the related literature. As a result, existing language models struggle to generate technical summaries that are on par with those produced by biomedical experts, given the absence of domain-specific background knowledge. This paper aims to enhance the performance of language models in biomedical abstractive summarisation by aggregating knowledge from external papers cited within the source article. We propose a novel attention-based citation aggregation model that integrates domain-specific knowledge from citation papers, allowing neural networks to generate summaries by leveraging both the paper content and relevant knowledge from citation papers. Furthermore, we construct and release a large-scale biomedical summarisation dataset that serves as a foundation for our research. Extensive experiments demonstrate that our model outperforms state-of-the-art approaches and achieves substantial improvements in abstractive biomedical text summarisation.",
}



@inproceedings{goldsack-etal-2023-biolaysumm,
    abbr="BioNLP2023",
    selected=True,
    pdf="https://aclanthology.org/2023.bionlp-1.44",
    title = "Overview of the BioLaySumm 2023 Shared Task on Lay Summarization of Biomedical Research Articles",
    author = "Goldsack, Tomas  and
      Luo, Zheheng  and
      Xie, Qianqian  and
      Scarton, Carolina  and
      Shardlow, Matthew  and
      Ananiadou, Sophia  and
      Lin, Chenghua",
    booktitle = "The 22nd Workshop on Biomedical Natural Language Processing and BioNLP Shared Tasks.",
    month = July,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.bionlp-1.44",
    pages = "468--477",
    arxiv = "2309.17332",
    abstract = "This paper presents the results of the shared task on Lay Summarisation of Biomedical Research Articles (BioLaySumm), hosted at the BioNLP Workshop at ACL 2023. The goal of this shared task is to develop abstractive summarisation models capable of generating {``}lay summaries{''} (i.e., summaries that are comprehensible to non-technical audiences) in both a controllable and non-controllable setting.There are two subtasks: 1) Lay Summarisation, where the goal is for participants to build models for lay summary generation only, given the full article text and the corresponding abstract as input; and2) Readability-controlled Summarisation, where the goal is for participants to train models to generate both the technical abstract and the lay summary, given an article{'}s main text as input.In addition to overall results, we report on the setup and insights from the BioLaySumm shared task, which attracted a total of 20 participating teams across both subtasks.",
}

@inproceedings{10.1007/978-3-031-28244-7_23,
  abbr="ECIR2023",
  selected=True,
  pdf="https://link.springer.com/chapter/10.1007/978-3-031-28244-7_23",
  abstract = {Scientific articles tend to follow a standardised discourse that enables a reader to quickly identify and extract useful or important information. We hypothesise that such structural conventions are strongly influenced by the scientific domain (e.g., Computer Science, Chemistry, etc.) and explore this through a novel extractive algorithm that utilises domain-specific discourse information for the task of abstract generation. In addition to being both simple and lightweight, the proposed algorithm constructs summaries in a structured and interpretable manner. In spite of these factors, we show that our approach outperforms strong baselines on the arXiv scientific summarisation dataset in both automatic and human evaluations, confirming that a scientific article's domain strongly influences its discourse structure and can be leveraged to effectively improve its summarisation. Our code can be found at: https://github.com/TGoldsack1/DodoRank.},
  address = {Cham},
  author = {Goldsack, Tomas and Zhang, Zhihao and Lin, Chenghua and Scarton, Carolina},
  booktitle = {Advances in Information Retrieval.},
  editor = {Kamps, Jaap and Goeuriot, Lorraine and Crestani, Fabio and Maistro, Maria and Joho, Hideo and Davis, Brian and Gurrin, Cathal and Kruschwitz, Udo and Caputo, Annalina},
  isbn = {978-3-031-28244-7},
  pages = {361--376},
  publisher = {Springer Nature Switzerland},
  title = {{Domain-Driven and Discourse-Guided Scientific Summarisation}},
  month = April,
  year = {2023}
}

@inproceedings{goldsack-etal-2022-making,
    abbr="EMNLP2022",
    selected=True,
    arxiv="2210.09932",
    code="https://github.com/TGoldsack1/Corpora_for_Lay_Summarisation",
    pdf="https://aclanthology.org/2022.emnlp-main.724",
    title = "Making Science Simple: Corpora for the Lay Summarisation of Scientific Literature",
    author = "Goldsack, Tomas  and
      Zhang, Zhihao  and
      Lin, Chenghua  and
      Scarton, Carolina",
    booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing.",
    month = December,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.emnlp-main.724",
    pages = "10589--10604",
    abstract = "Lay summarisation aims to jointly summarise and simplify a given text, thus making its content more comprehensible to non-experts.Automatic approaches for lay summarisation can provide significant value in broadening access to scientific literature, enabling a greater degree of both interdisciplinary knowledge sharing and public understanding when it comes to research findings. However, current corpora for this task are limited in their size and scope, hindering the development of broadly applicable data-driven approaches. Aiming to rectify these issues, we present two novel lay summarisation datasets, PLOS (large-scale) and eLife (medium-scale), each of which contains biomedical journal articles alongside expert-written lay summaries.We provide a thorough characterisation of our lay summaries, highlighting differing levels of readability and abstractivenessbetween datasets that can be leveraged to support the needs of different applications.Finally, we benchmark our datasets using mainstream summarisation approaches and perform a manual evaluation with domain experts, demonstrating their utility and casting light on the key challenges of this task.",
}


